{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed702b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\"\"\"\n",
    "pip install youtube-transcript-api\n",
    "pip install youtube-transcript-api --upgrade\n",
    "pip install --upgrade youtube-transcript-api\n",
    "pip install nltk\n",
    "pip install pandas\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b19e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import tiktoken\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8c693",
   "metadata": {},
   "source": [
    "# Calling API the youtube video transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebada92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = YouTubeTranscriptApi()\n",
    "\n",
    "def get_english_transcript(video_id: str) -> str | None:\n",
    "    try:\n",
    "        data = api.fetch(video_id, [\"en\"])\n",
    "        return \" \".join(s.text for s in data)\n",
    "    except NoTranscriptFound:\n",
    "        print(f\"Skipping {video_id} (no English transcript)\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1833156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [\"YBF9c2mCGME\", \"G0NCHag1rKc\", \"epgQ-sAr0l8\", \"3EgYr7jR4NI\", \"_AadMC3mzSk\"]\n",
    "\n",
    "records = []\n",
    "for vid in video_ids:\n",
    "    text = get_english_transcript(vid)\n",
    "    if text is None:\n",
    "        continue\n",
    "    records.append({\"video_id\": vid, \"transcript\": text})\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345bfe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id                                         transcript\n",
      "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...\n",
      "1  G0NCHag1rKc  [Music] welcome to the full Security Plus cour...\n",
      "2  epgQ-sAr0l8  this is how I would study for the Security Plu...\n",
      "3  3EgYr7jR4NI  DION: Hello, and\\nwelcome to the course. I am ...\n",
      "4  _AadMC3mzSk  in this video we will break down every single ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191122ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocesing, chunking and creation of the dataframe for the youtube video transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4160172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>chunks</th>\n",
       "      <th>Processed_Text_chunk</th>\n",
       "      <th>chunk_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBF9c2mCGME</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>[Are you struggling to pass the CompTIA Securi...</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBF9c2mCGME</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>[Are you struggling to pass the CompTIA Securi...</td>\n",
       "      <td>for lateral movement or data. So let me furthe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBF9c2mCGME</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>[Are you struggling to pass the CompTIA Securi...</td>\n",
       "      <td>server and if due to any reason one of the ser...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBF9c2mCGME</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>[Are you struggling to pass the CompTIA Securi...</td>\n",
       "      <td>available for implementing security controls. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YBF9c2mCGME</td>\n",
       "      <td>Are you struggling to pass the CompTIA Securit...</td>\n",
       "      <td>[Are you struggling to pass the CompTIA Securi...</td>\n",
       "      <td>access and manage the organization resources. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript  \\\n",
       "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...   \n",
       "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...   \n",
       "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...   \n",
       "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...   \n",
       "0  YBF9c2mCGME  Are you struggling to pass the CompTIA Securit...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  [Are you struggling to pass the CompTIA Securi...   \n",
       "0  [Are you struggling to pass the CompTIA Securi...   \n",
       "0  [Are you struggling to pass the CompTIA Securi...   \n",
       "0  [Are you struggling to pass the CompTIA Securi...   \n",
       "0  [Are you struggling to pass the CompTIA Securi...   \n",
       "\n",
       "                                Processed_Text_chunk  chunk_number  \n",
       "0  Are you struggling to pass the CompTIA Securit...             1  \n",
       "0  for lateral movement or data. So let me furthe...             2  \n",
       "0  server and if due to any reason one of the ser...             3  \n",
       "0  available for implementing security controls. ...             4  \n",
       "0  access and manage the organization resources. ...             5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.replace('\\ufeff', '')\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.replace(\"[Music]\", \"\").replace(\"[music]\", \"\").strip()\n",
    "    # keep your current tokenization / cleaning here if you still want it\n",
    "    return text\n",
    "\n",
    "# 1) tiktoken length function (for token-based chunk size)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text: str) -> int:\n",
    "    tokens = tokenizer.encode(text, disallowed_special=())\n",
    "    return len(tokens)\n",
    "\n",
    "# 2) create the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,          # about 400 tokens\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# 3) split each transcript into chunks\n",
    "df[\"chunks\"] = df[\"transcript\"].apply(lambda text: text_splitter.split_text(text))\n",
    "\n",
    "# 4) preprocess EACH chunk and keep them as a list\n",
    "def preprocess_chunk_list(chunk_list):\n",
    "    return [preprocess_text(chunk) for chunk in chunk_list]\n",
    "\n",
    "df[\"Processed_chunks\"] = df[\"chunks\"].apply(preprocess_chunk_list)\n",
    "\n",
    "# 5) explode into multiple rows (one per processed chunk)\n",
    "df_exploded = df.explode(\"Processed_chunks\")\n",
    "\n",
    "# 6) add chunk number per video_id\n",
    "df_exploded[\"chunk_number\"] = df_exploded.groupby(\"video_id\").cumcount() + 1\n",
    "\n",
    "# 7) rename the exploded column for clarity\n",
    "df_exploded = df_exploded.rename(columns={\"Processed_chunks\": \"Processed_Text_chunk\"})\n",
    "\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e424c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      video_id  chunk_number  \\\n",
      "0  YBF9c2mCGME             1   \n",
      "0  YBF9c2mCGME             2   \n",
      "0  YBF9c2mCGME             3   \n",
      "0  YBF9c2mCGME             4   \n",
      "0  YBF9c2mCGME             5   \n",
      "\n",
      "                                Processed_Text_chunk  \n",
      "0  Are you struggling to pass the CompTIA Securit...  \n",
      "0  for lateral movement or data. So let me furthe...  \n",
      "0  server and if due to any reason one of the ser...  \n",
      "0  available for implementing security controls. ...  \n",
      "0  access and manage the organization resources. ...  \n"
     ]
    }
   ],
   "source": [
    "# 8) Defining final dataframe\n",
    "clean_text = df_exploded[[\"video_id\",\"chunk_number\", \"Processed_Text_chunk\"]]\n",
    "print(clean_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Obtaining CSV file\n",
    "clean_text.to_csv(\"clean_text.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
